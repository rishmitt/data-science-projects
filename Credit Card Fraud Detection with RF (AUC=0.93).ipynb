{"cells":[{"metadata":{"_kg_hide-input":false,"trusted":false},"cell_type":"code","source":"library(randomForest)\nlibrary(caret)\nlibrary(gridExtra)\nlibrary(grid)\nlibrary(ggplot2)\nlibrary(lattice)\nlibrary(corrplot)\nlibrary(pROC)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(formattable)\nlibrary(dplyr)\noptions(knitr.table.format = \"html\") \n```\n\n# Introduction\n\nThis kernel uses and modifies code from \n[https://www.r-bloggers.com/illustrated-guide-to-roc-and-auc/](https://www.r-bloggers.com/illustrated-guide-to-roc-and-auc/).\n\n\nWe input the data.\n```{r read_data}\nraw.data <- read.csv(\"../input/creditcard.csv\")\n```\n\n# Utility functions\n\n\nWe will use a function for calculation of ROC and AUC.\n\n\n```{r utils_functions}\n#calculate ROC (https://en.wikipedia.org/wiki/Receiver_operating_characteristic)\ncalculate_roc <- function(verset, cost_of_fp, cost_of_fn, n=100) {\n  \n  tp <- function(verset, threshold) {\n    sum(verset$predicted >= threshold & verset$Class == 1)\n  }\n  \n  fp <- function(verset, threshold) {\n    sum(verset$predicted >= threshold & verset$Class == 0)\n  }\n  \n  tn <- function(verset, threshold) {\n    sum(verset$predicted < threshold & verset$Class == 0)\n  }\n  \n  fn <- function(verset, threshold) {\n    sum(verset$predicted < threshold & verset$Class == 1)\n  }\n  \n  tpr <- function(verset, threshold) {\n    sum(verset$predicted >= threshold & verset$Class == 1) / sum(verset$Class == 1)\n  }\n  \n  fpr <- function(verset, threshold) {\n    sum(verset$predicted >= threshold & verset$Class == 0) / sum(verset$Class == 0)\n  }\n  \n  cost <- function(verset, threshold, cost_of_fp, cost_of_fn) {\n    sum(verset$predicted >= threshold & verset$Class == 0) * cost_of_fp + \n      sum(verset$predicted < threshold & verset$Class == 1) * cost_of_fn\n  }\n  fpr <- function(verset, threshold) {\n    sum(verset$predicted >= threshold & verset$Class == 0) / sum(verset$Class == 0)\n  }\n  \n  threshold_round <- function(value, threshold)\n  {\n    return (as.integer(!(value < threshold)))\n  }\n  #calculate AUC (https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve)\n  auc_ <- function(verset, threshold) {\n    auc(verset$Class, threshold_round(verset$predicted,threshold))\n  }\n  \n  roc <- data.frame(threshold = seq(0,1,length.out=n), tpr=NA, fpr=NA)\n  roc$tp <- sapply(roc$threshold, function(th) tp(verset, th))\n  roc$fp <- sapply(roc$threshold, function(th) fp(verset, th))\n  roc$tn <- sapply(roc$threshold, function(th) tn(verset, th))\n  roc$fn <- sapply(roc$threshold, function(th) fn(verset, th))\n  roc$tpr <- sapply(roc$threshold, function(th) tpr(verset, th))\n  roc$fpr <- sapply(roc$threshold, function(th) fpr(verset, th))\n  roc$cost <- sapply(roc$threshold, function(th) cost(verset, th, cost_of_fp, cost_of_fn))\n  roc$auc <-  sapply(roc$threshold, function(th) auc_(verset, th))\n  \n  return(roc)\n}\n```\n\nThe following functions is for graphical representation of ROC, AUC and cost function.\n\n```{r plot_roc_auc_cost_functions}\nplot_roc <- function(roc, threshold, cost_of_fp, cost_of_fn) {\n  library(gridExtra)\n  \n  norm_vec <- function(v) (v - min(v))/diff(range(v))\n  \n  idx_threshold = which.min(abs(roc$threshold-threshold))\n  \n  col_ramp <- colorRampPalette(c(\"green\",\"orange\",\"red\",\"black\"))(100)\n  col_by_cost <- col_ramp[ceiling(norm_vec(roc$cost)*99)+1]\n  p_roc <- ggplot(roc, aes(fpr,tpr)) + \n    geom_line(color=rgb(0,0,1,alpha=0.3)) +\n    geom_point(color=col_by_cost, size=2, alpha=0.5) +\n    labs(title = sprintf(\"ROC\")) + xlab(\"FPR\") + ylab(\"TPR\") +\n    geom_hline(yintercept=roc[idx_threshold,\"tpr\"], alpha=0.5, linetype=\"dashed\") +\n    geom_vline(xintercept=roc[idx_threshold,\"fpr\"], alpha=0.5, linetype=\"dashed\")\n  \n  p_auc <- ggplot(roc, aes(threshold, auc)) +\n    geom_line(color=rgb(0,0,1,alpha=0.3)) +\n    geom_point(color=col_by_cost, size=2, alpha=0.5) +\n    labs(title = sprintf(\"AUC\")) +\n    geom_vline(xintercept=threshold, alpha=0.5, linetype=\"dashed\")\n  \n  p_cost <- ggplot(roc, aes(threshold, cost)) +\n    geom_line(color=rgb(0,0,1,alpha=0.3)) +\n    geom_point(color=col_by_cost, size=2, alpha=0.5) +\n    labs(title = sprintf(\"cost function\")) +\n    geom_vline(xintercept=threshold, alpha=0.5, linetype=\"dashed\")\n  \n  sub_title <- sprintf(\"threshold at %.2f - cost of FP = %d, cost of FN = %d\", threshold, cost_of_fp, cost_of_fn)\n  # \n  grid.arrange(p_roc, p_auc, p_cost, ncol=2,sub=textGrob(sub_title, gp=gpar(cex=1), just=\"bottom\"))\n}\n```\n\nThe follwing function is for showing a confusion matrix.\n\n```{r show_confusion_matrix}\nplot_confusion_matrix <- function(verset, sSubtitle) {\n    tst <- data.frame(round(verset$predicted,0), verset$Class)\n    opts <-  c(\"Predicted\", \"True\")\n    names(tst) <- opts\n    cf <- plyr::count(tst)\n    cf[opts][cf[opts]==0] <- \"Not Fraud\"\n    cf[opts][cf[opts]==1] <- \"Fraud\"\n    \n    ggplot(data =  cf, mapping = aes(x = True, y = Predicted)) +\n      labs(title = \"Confusion matrix\", subtitle = sSubtitle) +\n      geom_tile(aes(fill = freq), colour = \"grey\") +\n      geom_text(aes(label = sprintf(\"%1.0f\", freq)), vjust = 1) +\n      scale_fill_gradient(low = \"lightblue\", high = \"blue\") +\n      theme_bw() + theme(legend.position = \"none\")\n  \n}\n\n\n```\n\nThe function will be called to compare the predicted value with the real values.\n\n\n# Explore the data\n\nLet's glimpse the data:\n\nColumns and rows:\n\n```{r rows_cols}\nsprintf(\"Rows: %d Columns: %d\",nrow(raw.data), length(names(raw.data)))\n```\n\nSee first few rows of data:\n\n```{r glimpse_data}\nhead(raw.data,10) %>%\n  kable( \"html\", escape=F, align=\"c\") %>%\n   kable_styling(bootstrap_options = \"striped\", full_width = F, position = \"center\")\n``` \n\nThere are totally 31 columns in the data. One column, `Class` is the target value; it is a binary value, can\nhave either `0` (not fraud) or `1` (fraud) value. Another two columns have clear meaning: `Amount` is the\namount of the transaction; `Time` is the time of the transaction. The rest of the features (28), anonymized, are\nnamed from `V1` to `V28`.\nThe data is highly unbalanced with respect of `Class` variable values. There are only\n``r nrow(raw.data[raw.data$Class==1,])/nrow(raw.data)*100``% of the rows with value `Class = 1`. \nTypically, in such cases, we can either choose to preserve the data unbalancing or use a oversampling (of the data with \nminority value of target variable) or undersampling (of the data with majority value of the target variable).\nHere we will just preserve the unbalancing of the data. In terms of validation of the result, we will see that\nusual metrix, using a confusion matrix or accuracy are not the most relevant and will be prefered alternative\nsolutions using AUC.\n\n\n# Correlations\n\nWe represent the Pearson correlation for the data.\n\n```{r correlation}\ncorrelations <- cor(raw.data,method=\"pearson\")\ncorrplot(correlations, number.cex = .9, method = \"circle\", type = \"full\", tl.cex=0.8,tl.col = \"black\")\n```\nWe can observe that most of the data features are not correlated. This is because before publishing,\nmost of the features were presented to a Principal Component Analysis (PCA) algorithm.\nThe features `V1` to `V28` are most probably the Principal Components resulted after propagating\nthe real features through PCA. We do not know if the numbering of the features reflects the importance\nof the Principal Components. This information might be checked partially using the Variable Importance\nfrom Random Forest.\n\n# Model\n\nAfter we split the data in a training and test set, we create the RF model using the training set.\n\n```{r model}\nnrows <- nrow(raw.data)\nset.seed(314)\nindexT <- sample(1:nrow(raw.data), 0.7 * nrows)\n\n#separate train and validation set\ntrainset = raw.data[indexT,]\nverset =   raw.data[-indexT,]\n\nn <- names(trainset)\nrf.form <- as.formula(paste(\"Class ~\", paste(n[!n %in% \"Class\"], collapse = \" + \")))\n\ntrainset.rf <- randomForest(rf.form,trainset,ntree=100,importance=T)\n```\n\nFor the trained model, let's see visualize the variable importance.\n\n```{r variable_importance}\nvarimp <- data.frame(trainset.rf$importance)\n\n  vi1 <- ggplot(varimp, aes(x=reorder(rownames(varimp),IncNodePurity), y=IncNodePurity)) +\n  geom_bar(stat=\"identity\", fill=\"tomato\", colour=\"black\") +\n  coord_flip() + theme_bw(base_size = 8) +\n  labs(title=\"Prediction using RandomForest with 100 trees\", subtitle=\"Variable importance (IncNodePurity)\", x=\"Variable\", y=\"Variable importance (IncNodePurity)\")\n  \n  vi2 <- ggplot(varimp, aes(x=reorder(rownames(varimp),X.IncMSE), y=X.IncMSE)) +\n  geom_bar(stat=\"identity\", fill=\"lightblue\", colour=\"black\") +\n  coord_flip() + theme_bw(base_size = 8) +\n  labs(title=\"Prediction using RandomForest with 100 trees\", subtitle=\"Variable importance (%IncMSE)\", x=\"Variable\", y=\"Variable importance (%IncMSE)\")\n\ngrid.arrange(vi1, vi2, ncol=2)\n```\n\n# Prediction\n\nLet's use the trained model for prediction of the Fraud/Not Fraud Class for the test set.\n\n```{r verif}\nverset$predicted <- predict(trainset.rf ,verset)\n```\n\nFor the threshold at 0.5, let's represent the Confusion matrix.\n\n```{r fig.width=4, fig.height=4, confusion_matrix_}\nplot_confusion_matrix(verset, \"Random Forest with 100 trees\")\n```\n\nFor such a problem, where the number of TP is very small in comparison with the number of TN, the Confusion Matrix is less useful, since it is important to use a metric that include evaluation of FP and FN as well. It is important to minimize as much as possible the number of FN (Predicted: Not Fraud and True: Fraud) since their cost could be very large. Tipically AUC is used for such cases.\n\nLet's calculate the TP, FP, TN, FN, ROC, AUC and cost for threshold with values\nbetween 0 and 1 (100 values equaly distributed) and cost 1 for TN and 10 for FN.\n\n```{r comp_roc_auc_cost_}\nroc <- calculate_roc(verset, 1, 10, n = 100)\n\nmincost <- min(roc$cost)\nroc %>%\n mutate(\n   auc = ifelse(cost == mincost,\n                  cell_spec(sprintf(\"%.5f\", auc), \"html\", color = \"green\", background = \"lightblue\", bold = T),\n                  cell_spec(sprintf(\"%.5f\", auc), \"html\", color = \"black\", bold = F))\n  ) %>%\n  kable( \"html\", escape=F, align=\"c\") %>%\n   kable_styling(bootstrap_options = \"striped\", full_width = F, position = \"center\") %>%\n   scroll_box(height = \"600px\")\n```\n\n\nLet's plot the ROC, AUC and cost functions for a ref. threshold of 0.3.\n\n```{r plot_roc_auc_cost_}\nthreshold = 0.3\nplot_roc(roc, threshold, 1, 10)\n```  \n\n\n# Conclusions  \n\n\nThe calculated accuracy is not very relevant in the conditions where there is a very large unbalance between\nthe number of `fraud` and `non-fraud` events in the dataset. In such cases, we can see a very large accuracy.\nMore relevant is the value of ROC-AUC (Area Under Curve for the Receiver Operator Characteristic). The value\nobtained (0.93) is relativelly good, considering that we did not performed any tunning, working with default\nRF algorithm parameters.  \n\n\n\n# References  \n\n[1] Receiver Operating Characteristic, https://en.wikipedia.org/wiki/Receiver_operating_characteristic  \n[2] Area under curve, https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve  \n[3] Computing and visualizing PCA in R, https://www.r-bloggers.com/computing-and-visualizing-pca-in-r/  \n\n","execution_count":0,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}